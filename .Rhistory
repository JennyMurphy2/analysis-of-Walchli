effect = "factor.A",
alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.95, power = 0.95, step = 0.001)
#BUCSS - 0.5 assurance level
BUCSS_0.5 <- ss.power.wa(F.observed=ori_Fval, N=N, levels.A=3, levels.B = NULL,
effect = "factor.A",
alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.5, power = 0.95, step = 0.001)
BUCSS_0.5
#BUCSS - 0.8 assurance level
BUCSS_0.8 <- ss.power.wa(F.observed=ori_Fval, N=N, levels.A=3, levels.B = NULL,
effect = "factor.A",
alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.8, power = 0.95, step = 0.001)
BUCSS_0.8
#BUCSS - 0.95 assurance level
BUCSS_0.95 <- ss.power.wa(F.observed=ori_Fval, N=N, levels.A=3, levels.B = NULL,
effect = "factor.A",
alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.95, power = 0.95, step = 0.001)
ori_pval <- 0.004
N <- 12
df1 <- 2
df2 <- 22
pval = ori_pval
quantile = 1 - pval
ori_Fval <- qf(quantile, df1=df1, df2=df2)
ori_Fval
ori_pval <- 0.004
N <- 12
df1 <- 2
df2 <- 11
pval = ori_pval
quantile = 1 - pval
ori_Fval <- qf(quantile, df1=df1, df2=df2)
ori_Fval
ori_pval <- 0.004
N <- 12
df1 <- 2
df2 <- 22
pval = ori_pval
quantile = 1 - pval
ori_Fval <- qf(quantile, df1=df1, df2=df2)
ori_Fval
#Calculating es and its CI
#ANOVA - Calculating partial eta squared using F statistic and df
#dfm = degrees of freedom for the model/IV/between
#dfe = degrees of freedom for the error/residual/within
es <- eta.F(dfm=df1, dfe=df2, Fvalue=ori_Fval, a = 0.05)
es
f <- eta2_to_f(es$eta)
f
f_low <- eta2_to_f(es$etalow)
f_low
#using original effect size point estimate
#sphercity was corrected in original study therefore leave nscor=1
#type = 1 for within effect
webpower <- wp.rmanova(n = NULL, ng = 1, nm = 3, f = f, nscor = 1,
alpha = 0.05, power = 0.95, type = 1)
webpower
#lower bound confidence interval converted to cohen's f using excel spreadsheet
#sphercity was corrected in original study therefore leave nscor=1
#type = 1 for within effect
webpower_low <- wp.rmanova(n = NULL, ng = 1, nm = 3, f = f_low, nscor = 1,
alpha = 0.05, power = 0.95, type = 1)
webpower_low
#BUCSS - 0.5 assurance level
BUCSS_0.5 <- ss.power.wa(F.observed=ori_Fval, N=N, levels.A=3, levels.B = NULL,
effect = "factor.A",
alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.5, power = 0.95, step = 0.001)
BUCSS_0.5
#BUCSS - 0.8 assurance level
BUCSS_0.8 <- ss.power.wa(F.observed=ori_Fval, N=N, levels.A=3, levels.B = NULL,
effect = "factor.A",
alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.8, power = 0.95, step = 0.001)
BUCSS_0.8
#BUCSS - 0.95 assurance level
BUCSS_0.95 <- ss.power.wa(F.observed=ori_Fval, N=N, levels.A=3, levels.B = NULL,
effect = "factor.A",
alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.95, power = 0.95, step = 0.001)
ori_pval <- 0.009
N <- 12
df1 <- 2
df2 <- 22
pval = ori_pval
quantile = 1 - pval
ori_Fval <- qf(quantile, df1=df1, df2=df2)
ori_Fval
#Calculating es and its CI
#ANOVA - Calculating partial eta squared using F statistic and df
#dfm = degrees of freedom for the model/IV/between
#dfe = degrees of freedom for the error/residual/within
es <- eta.F(dfm=df1, dfe=df2, Fvalue=ori_Fval, a = 0.05)
es
f <- eta2_to_f(es$eta)
f
f_low <- eta2_to_f(es$etalow)
f_low
#using original effect size point estimate
#sphercity was corrected in original study therefore leave nscor=1
#type = 1 for within effect
webpower <- wp.rmanova(n = NULL, ng = 1, nm = 3, f = f, nscor = 1,
alpha = 0.05, power = 0.95, type = 1)
webpower
library("faux")
#Load packages
if(!require(WebPower)){install.packages('WebPower')}
library(WebPower)
if(!require(BUCSS)){install.packages('BUCSS')}
library(BUCSS)
library(tinytex)
if(!require(MBESS)){install.packages('MBESS')}
library(MBESS)
library(MOTE)
library(effectsize)
#Load packages
if(!require(BUCSS)){install.packages('BUCSS')}
library(BUCSS)
library(tinytex)
if(!require(MBESS)){install.packages('MBESS')}
library(MBESS)
library(MOTE)
library(effectsize)
library(WebPower)
# ori_pval < 0.001
N <- 10
df1 <- 3
df2 <- 27
pval = ori_pval
# ori_pval < 0.001
N <- 10
df1 <- 3
df2 <- 27
ori_pval <- 0.0499
pval = ori_pval
quantile = 1 - pval
ori_Fval <- qf(quantile, df1=df1, df2=df2)
ori_Fval
#Calculating es and its CI
#ANOVA - Calculating partial eta squared using F statistic and df
#dfm = degrees of freedom for the model/IV/between
#dfe = degrees of freedom for the error/residual/within
es <- eta.F(dfm=df1, dfe=df2, Fvalue=ori_Fval, a = 0.05)
es
f <- eta2_to_f(es$eta)
f
f_low <- eta2_to_f(es$etalow)
f_low
#using original effect size point estimate
#lower bound correction for sphercity 1/(k-1) where k is no of conditions
#type = 1 for within effect
wp <- wp.rmanova(n = NULL, ng = 1, nm = 6, f = f, nscor = 1,
alpha = 0.05, power = 0.95, type = 1)
wp
#using original effect size point estimate
#lower bound correction for sphercity 1/(k-1) where k is no of conditions
#type = 1 for within effect
wp_low <- wp.rmanova(n = NULL, ng = 1, nm = 6, f = f_low, nscor = 1,
alpha = 0.05, power = 0.95, type = 1)
#using original effect size point estimate
#lower bound correction for sphercity 1/(k-1) where k is no of conditions
#type = 1 for within effect
wp <- wp.rmanova(n = NULL, ng = 1, nm = 3, f = f, nscor = 1,
alpha = 0.05, power = 0.95, type = 1)
wp
#using original effect size point estimate
#lower bound correction for sphercity 1/(k-1) where k is no of conditions
#type = 1 for within effect
wp_low <- wp.rmanova(n = NULL, ng = 1, nm = 3, f = f_low, nscor = 1,
alpha = 0.05, power = 0.95, type = 1)
#BUCSS - 0.5 assurance level
BUCSS_0.5 <- ss.power.wa(F.observed=ori_Fval, N=N, levels.A=3, levels.B = NULL,
effect = "factor.A",
alpha.prior = 0.05, alpha.planned = 0.05, assurance = 0.5,
power = 0.95, step = 0.001)
# ori_pval < 0.001
N <- 10
df1 <- 2
df2 <- 27
ori_pval <- 0.0499
pval = ori_pval
quantile = 1 - pval
ori_Fval <- qf(quantile, df1=df1, df2=df2)
ori_Fval
#Calculating es and its CI
#ANOVA - Calculating partial eta squared using F statistic and df
#dfm = degrees of freedom for the model/IV/between
#dfe = degrees of freedom for the error/residual/within
es <- eta.F(dfm=df1, dfe=df2, Fvalue=ori_Fval, a = 0.05)
es
f <- eta2_to_f(es$eta)
f
f_low <- eta2_to_f(es$etalow)
f_low
#using original effect size point estimate
#lower bound correction for sphercity 1/(k-1) where k is no of conditions
#type = 1 for within effect
wp <- wp.rmanova(n = NULL, ng = 1, nm = 3, f = f, nscor = 1,
alpha = 0.05, power = 0.95, type = 1)
wp
#using original effect size point estimate
#lower bound correction for sphercity 1/(k-1) where k is no of conditions
#type = 1 for within effect
wp_low <- wp.rmanova(n = NULL, ng = 1, nm = 3, f = f_low, nscor = 1,
alpha = 0.05, power = 0.95, type = 1)
#BUCSS - 0.5 assurance level
BUCSS_0.5 <- ss.power.wa(F.observed=ori_Fval, N=N, levels.A=3, levels.B = NULL,
effect = "factor.A",
alpha.prior = 0.05, alpha.planned = 0.05, assurance = 0.5,
power = 0.95, step = 0.001)
#Load packages
if(!require(BUCSS)){install.packages('BUCSS')}
library(BUCSS)
library(tinytex)
if(!require(MBESS)){install.packages('MBESS')}
library(MBESS)
library(MOTE)
library(effectsize)
library(pwr)
ori_pval <- 0.00099
N <- 14
m1 <- 42.80
sd1 <- 6.46
m2 <- 37.03
sd2 <- 6.38
pval = ori_pval/2 # for two-tailed
quantile = 1 - pval
tval <- qt(quantile, df = 11, lower.tail = FALSE)
tval <- abs(tval)
#Calculating es and its CI
#PAIRED SAMPLES - Calculating dz and its CI using t value
dz <- d.dep.t.diff.t(t=tval, n=N, a = 0.05)
dz
#using original effect size point estimate
pwr <- pwr.t.test(n = NULL, d = dz$d, sig.level = 0.05, power = 0.95,
type = "paired",
alternative = "two.sided")
pwr
#using lower bound confidence interval of the original effect size
#using lower bound CI of dz even though this is not what they reported
pwr_low <- pwr.t.test(n = NULL, d = dz$dlow, sig.level = 0.05, power = 0.95,
type = "paired",
alternative = "two.sided")
pwr_low
#BUCSS - 0.5 assurance level
BUCSS_0.5 <- ss.power.dt(t.observed = tval, N=N, alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.5, power = 0.95, step = 0.001)
BUCSS_0.5
#BUCSS - 0.8 assurance level
BUCSS_0.8 <- ss.power.dt(t.observed = tval, N=N, alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.8, power = 0.95, step = 0.001)
BUCSS_0.8
#BUCSS - 0.95 assurance level
BUCSS_0.95 <- ss.power.dt(t.observed = tval, N=N, alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.95, power = 0.95, step = 0.001)
BUCSS_0.95
View(dz)
install.packages("kableExtra")
#Load packages
if(!require(BUCSS)){install.packages('BUCSS')}
library(BUCSS)
library(tinytex)
if(!require(MBESS)){install.packages('MBESS')}
library(MBESS)
library(MOTE)
library(effectsize)
library(pwr)
#BUCSS - 0.5 assurance level
BUCSS_0.5 <- ss.power.dt(t.observed = tval, N=N, alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.5, power = 0.95, step = 0.001)
ori_pval <- 0.005
N <- 12
reported_es <- 0.84
m1 <- 10.58
sd1 <- 2.07
m2 <- 8.9
sd2 <- 1.8
pval = ori_pval/2 # for two-tailed
quantile = 1 - pval
tval <- qt(quantile, df = 11, lower.tail = FALSE)
tval <- abs(tval)
#Calculating es and its CI
#PAIRED SAMPLES - Calculating dz and its CI using t value
dz <- d.dep.t.diff.t(t=tval, n=N, a = 0.05)
dz
#INDEPENDENT SAMPLES - Calculating ds and its CI using t value
ds <- d.ind.t.t(t=tval, n1=N, n2=N, a = 0.05)
ds
# Cohen's dav
dav <- d.dep.t.avg(m1=m1, m2=m2, sd1=sd1, sd2=sd2, n=N, a = 0.05)
dav
# The reported effect size of 0.84 does not seem to be either dz or ds
# It seems closest to calculations of dav
#using original effect size point estimate
pwr <- pwr.t.test(n = NULL, d = reported_es, sig.level = 0.05, power = 0.95,
type = "paired",
alternative = "two.sided")
pwr
#using lower bound confidence interval of the original effect size
#using lower bound CI of dz even though this is not what they reported
pwr_low <- pwr.t.test(n = NULL, d = dav$dlow, sig.level = 0.05, power = 0.95,
type = "paired",
alternative = "two.sided")
pwr_low
#BUCSS - 0.5 assurance level
BUCSS_0.5 <- ss.power.dt(t.observed = tval, N=N, alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.5, power = 0.95, step = 0.001)
BUCSS_0.5
#BUCSS - 0.8 assurance level
BUCSS_0.8 <- ss.power.dt(t.observed = tval, N=N, alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.8, power = 0.95, step = 0.001)
BUCSS_0.8
#BUCSS - 0.95 assurance level
BUCSS_0.95 <- ss.power.dt(t.observed = tval, N=N, alpha.prior = 0.05, alpha.planned = 0.05,
assurance = 0.95, power = 0.95, step = 0.001)
# Load packages
library(stats)
library(rstatix)
library(TOSTER)
library(MOTE)
library(tidyverse)
# Load data --------------------------------------------------------------------
data <- read_csv("full_bench_press_data.csv")
library(TOSTER)
citation()
citation(TOSTER)
citation("TOSTER")
library(rstatix)
library(afex)
library(car)
library(broom)
library(emmeans)
library(stringr)
library(lmerTest)
library(tidyverse)
# Import and prepare data --------------------
data <- read_csv("jump_reward_data.csv")
setwd("~/Dropbox/PhD/Replication Analysis/Replication Analysis/Jasmin (jump reward)")
library(rstatix)
library(afex)
library(car)
library(broom)
library(emmeans)
library(stringr)
library(lmerTest)
library(tidyverse)
# Import and prepare data --------------------
data <- read_csv("jump_reward_data.csv")
View(data)
jump_data <- data %>%
select(subject, jumpheight_ne, jumpheight_af, jumpheight_re, jumpheight_afef, jumpheight_afre, jumpheight_afefre)
View(jump_data)
?pivot_longer
long_data <- jump_data %>%
pivot_longer(cols = starts_with("jump"),
names_to = "condition",
values_to = "jump_height")
View(long_data)
# mean and sd of data
summary <- long_data %>%
group_by(condition) %>%
summarize(overall_mean = mean(jump_height, na.rm=TRUE),
overall_sd = sd(jump_height, na.rm = TRUE))
View(summary)
mean and sd of data
anova_results <- afex::aov_4(jump_data ~ (condition|id),
data = long_data,
anova_table = list(es = "pes")) # partial eta squared
anova_results <- afex::aov_4(jump_data ~ (condition|subject),
data = long_data,
anova_table = list(es = "pes")) # partial eta squared
##afex::aov_4(continuous_var ~ group_var + (RM_var|id_var)
anova_results <- afex::aov_4(jump_height ~ (condition|subject),
data = long_data,
anova_table = list(es = "pes")) # partial eta squared
anova_results
summary(anova_results)
posthocresults <- pairs(data_emm, adjust = "bon") %>%
broom::tidy(conf.int = T)
data_emm <- anova_results %>%
emmeans::emmeans(~ condition, model = "multivariate")
data_emm
posthocresults <- pairs(data_emm, adjust = "bon") %>%
broom::tidy(conf.int = T)
posthocresults
long_data %>%
dplyr::group_by(condition) %>%
rstatix::shapiro_test(jump_height) # shapiro-wilk test on individual groups
long_data %>%
group_by(condition) %>%
identify_outliers(jump_height)
## Plots ---------
## violin
long_data %>%
ggplot(aes(condition, jump_height)) +
geom_violin(fill = "gray") +
geom_boxplot(width = .07,
fill = "white") +
geom_jitter(position = position_jitter(0.21)) +
stat_summary(fun = mean,
geom = "point",
shape = 18,
color = "red",
size = 5) +
theme_bw()
long_data %>%
ggplot(aes(sample = jump_height)) +    # make sure to include "sample = DV"
geom_qq() +
stat_qq_line() +
facet_wrap(~ condition,                   # Panel by group
labeller = label_both) +
theme_bw()
pes_rep = anova_results$anova_table$pes
df_rep = anova_results$anova_table$`den Df`
pes_ori = 0.348
df_ori = 85
rho_ori = 2*sqrt(pes_ori)-1
rho_rep = 2*sqrt(pes_rep)-1
rep_test = TOSTER::compare_cor(r2 = rho_ori,
df2 = df_ori,
r1 = rho_rep,
df1 = df_rep)
rep_test
options(scipen = 999)
rho_ori = 2*sqrt(pes_ori)-1
rho_rep = 2*sqrt(pes_rep)-1
rep_test = TOSTER::compare_cor(r2 = rho_ori,
df2 = df_ori,
r1 = rho_rep,
df1 = df_rep)
rep_test
setwd("~/Library/CloudStorage/Dropbox/PhD/Replication Analysis/Replication Analysis/Jasmin (jump reward)/analysis-of-Walchli2016-replication-study")
library(rstatix)
library(afex)
library(car)
library(broom)
library(emmeans)
library(stringr)
library(lmerTest)
library(tidyverse)
# Import and prepare data --------------------
data <- read_csv("jump_reward_data.csv")
# Prepare data ----------------
jump_data <- data %>%
select(subject, jumpheight_ne, jumpheight_af, jumpheight_re, jumpheight_afef, jumpheight_afre, jumpheight_afefre)
# convert to long data set
long_data <- jump_data %>%
pivot_longer(cols = starts_with("jump"),
names_to = "condition",
values_to = "jump_height")
# Descriptives
# mean and sd of data
summary <- long_data %>%
group_by(condition) %>%
summarize(count = n(),
mean = mean(jump_height, na.rm=TRUE),
sd = sd(jump_height, na.rm = TRUE))
## ANOVA -----
# RM ANOVA
##afex::aov_4(continuous_var ~ group_var + (RM_var|id_var)
anova_results <- afex::aov_4(jump_height ~ (condition|subject),
data = long_data,
anova_table = list(es = "pes")) # partial eta squared
anova_results
summary(anova_results)
nice(anova_results)
## Assumptions --------
### Normality test -------
long_data %>%
dplyr::group_by(condition) %>%
rstatix::shapiro_test(jump_height) # shapiro-wilk test on individual groups
### Outliers check --------
long_data %>%
group_by(condition) %>%
identify_outliers(jump_height)
## Plots ---------
## violin
long_data %>%
ggplot(aes(condition, jump_height)) +
geom_violin(fill = "gray") +
geom_boxplot(width = .07,
fill = "white") +
geom_jitter(position = position_jitter(0.21)) +
stat_summary(fun = mean,
geom = "point",
shape = 18,
color = "red",
size = 5) +
theme_bw()
# qq plot
long_data %>%
ggplot(aes(sample = jump_height)) +
geom_qq() +
stat_qq_line() +
facet_wrap(~ condition,                   # Panel by group
labeller = label_both) +
theme_bw()
# Replication test -----
pes_rep = anova_results$anova_table$pes
df_rep = anova_results$anova_table$`den Df`
pes_ori = 0.348
df_ori = 85
rho_ori = 2*sqrt(pes_ori)-1
rho_rep = 2*sqrt(pes_rep)-1
rep_test = TOSTER::compare_cor(r2 = rho_ori,
df2 = df_ori,
r1 = rho_rep,
df1 = df_rep)
rep_test
